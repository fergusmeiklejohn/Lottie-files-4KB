{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install OpenAI pakcages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: openai 0.28.0\n",
      "Uninstalling openai-0.28.0:\n",
      "  Successfully uninstalled openai-0.28.0\n",
      "Requirement already satisfied: pip in /Users/colafly/.pyenv/versions/lottie/lib/python3.11/site-packages (23.2.1)\n",
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/ae/59/911d6e5f1d7514d79c527067643376cddcf4cb8d1728e599b3b03ab51c69/openai-0.28.0-py3-none-any.whl.metadata\n",
      "  Using cached openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/colafly/.pyenv/versions/lottie/lib/python3.11/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/colafly/.pyenv/versions/lottie/lib/python3.11/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /Users/colafly/.pyenv/versions/lottie/lib/python3.11/site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/colafly/.pyenv/versions/lottie/lib/python3.11/site-packages (from requests>=2.20->openai) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/colafly/.pyenv/versions/lottie/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/colafly/.pyenv/versions/lottie/lib/python3.11/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/colafly/.pyenv/versions/lottie/lib/python3.11/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/colafly/.pyenv/versions/lottie/lib/python3.11/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/colafly/.pyenv/versions/lottie/lib/python3.11/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/colafly/.pyenv/versions/lottie/lib/python3.11/site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/colafly/.pyenv/versions/lottie/lib/python3.11/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/colafly/.pyenv/versions/lottie/lib/python3.11/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/colafly/.pyenv/versions/lottie/lib/python3.11/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: openai\n",
      "Successfully installed openai-0.28.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall --yes openai\n",
    "!pip install --upgrade pip\n",
    "!pip install openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.4\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-Tune OpenAI GPT3.5 model\n",
    "Step 1. generate >50 sample lottie animation instructions and save them as a JSON file named generated_prompt.json <br>\n",
    "Step 2. generate lottie files with GPT 4 model based on insturction in step 1<br>\n",
    "Step 3. manually import the generated lottie files into AE, and exportthem again (only keep 10-20 valid samples, other are not regonizable)<br>\n",
    "Step 4. construct fine-tune dataset with prompt and valid samples<br>\n",
    "Step 5. fine-tune openAI GPT3.5 with dataset<br>\n",
    "Step 6. apply fine-tuned model to generate new lottie animation files<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lottie_prompt(action):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are lottie file generator. lottie file should be inside code block ```json ```. format of lottie file: version is 5.12.1. layer is required. one shape should be in layer. a, p, o, r, s should be in both layer and shape,  hd = false. ip, op, sr, st should be in top level, layer, and shape. fill and transform should be parallel to shape json. for keyframe,  it should has two json objects with field i,o,s,t,ti,to.\"},\n",
    "        {\"role\": \"user\", \"content\": action}\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract json blob from GenAI response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_json_blob(paragraph):\n",
    "    # Define a regular expression pattern to match the JSON blob\n",
    "    pattern = r\"```json\\n(.+?)\\n```\"\n",
    "\n",
    "    # Use the re.search() function to find the first match of the pattern in the paragraph\n",
    "    match = re.search(pattern, paragraph, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        # If a match is found, extract the JSON blob from the match object\n",
    "        json_blob = match.group(1)\n",
    "\n",
    "        # Use the json.loads() function to parse the JSON blob into a Python object\n",
    "        json_obj = json.loads(json_blob)\n",
    "\n",
    "        # Return the Python object\n",
    "        return json_obj\n",
    "    else:\n",
    "        # If no match is found, return None\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate lottie files with gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('generated_prompt.json', 'r') as f:\n",
    "    o = json.load(f)\n",
    "    for json_obj in o['lottie_prompts'][:72]:\n",
    "        lo = generate_lottie_prompt(json_obj['description'])\n",
    "        try:\n",
    "            lo_extracted = extract_json_blob(lo)\n",
    "            print(lo_extracted)\n",
    "            if lo_extracted:\n",
    "                with open(f\"out/{json_obj['id']}.json\", 'w') as outfile:\n",
    "                    json.dump(lo_extracted, outfile)\n",
    "        except Exception as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create json blob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def create_json_object(number):\n",
    "    with open('./out/' + str(number) + '_ae.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        with open('generated_prompt.json', 'r') as lottie:\n",
    "            content = json.load(lottie)['lottie_prompts'][int(number)-1]['description']\n",
    "            json_obj = {\"messages\": [\n",
    "                            {\"role\": \"system\", \"content\": \"You are lottie file generator. lottie file should be inside code block ```json ```. format of lottie file: version is 5.12.1. layer is required. one shape should be in layer. a, p, o, r, s should be in both layer and shape,  hd = false. ip, op, sr, st should be in top level, layer, and shape. fill and transform should be parallel to shape json. for keyframe,  it should has two json objects with field i,o,s,t,ti,to.\"}, \n",
    "                            {\"role\": \"user\", \"content\": content}, \n",
    "                            {\"role\": \"assistant\", \"content\": json.dumps(data, ensure_ascii=False)}\n",
    "                        ]}\n",
    "        \n",
    "        return json_obj\n",
    "\n",
    "\n",
    "def create_jsonl(json_obj, output_file_path):\n",
    "    with open(output_file_path, 'a+') as f:\n",
    "        json.dump(json_obj, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 2, 4, 9, 25, 41, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77]:\n",
    "    create_jsonl(create_json_object(i), 'ft_0913.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apend_new_json_object(folder_path, file_name):\n",
    "    with open(os.path.join(folder_path, file_name), 'r') as f:\n",
    "        data = json.load(f)\n",
    "        json_obj = {\"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": \"You are lottie file generator. lottie file should be inside code block ```json ```. format of lottie file: version is 5.12.1. layer is required. one shape should be in layer. a, p, o, r, s should be in both layer and shape,  hd = false. ip, op, sr, st should be in top level, layer, and shape. fill and transform should be parallel to shape json. for keyframe,  it should has two json objects with field i,o,s,t,ti,to.\"}, \n",
    "                        {\"role\": \"user\", \"content\": file_name.split('.')[0]}, \n",
    "                        {\"role\": \"assistant\", \"content\": json.dumps(data, ensure_ascii=False)}\n",
    "                    ]}\n",
    "        \n",
    "        return json_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrow move up and disappear\n",
      "line rotate 360 degree\n",
      "zero expanding and contracting\n",
      "line expand and shrink horizontally\n",
      "bookmark shrink and expand\n",
      "arrow move up and down\n",
      "half circle path move up and down\n",
      "circle expanding and contracting\n",
      "camera rotate 45 degrees and back\n",
      "3  bouncing up and down\n",
      "triangle expanding and contracting\n",
      "line expand and shrink vertically\n",
      "triangle squeeze and release\n",
      "square move right and come back from left\n",
      "rectangle missing corner and release\n",
      "label rotate 10 degrees and back\n",
      "key rotate and move\n",
      "rectangle bouncing up and shake and down\n"
     ]
    }
   ],
   "source": [
    "folder_path = './out_0920/'\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Call the append_new_json_object() function for each file\n",
    "    print(file_name.split('.')[0])\n",
    "    create_jsonl(apend_new_json_object(folder_path, file_name), 'ft_0920.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the prepared dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-vnVISeDU2iquWAzkHA7BVx55\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file = openai.File.create(\n",
    "    file=open(\"ft_0920.jsonl\", \"rb\"),\n",
    "    purpose='fine-tune'\n",
    ")\n",
    "print(file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Fine-tune job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"id\": \"ftjob-0xdbLGx7lfkF6W2sOt9HZ1A7\",\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"created_at\": 1695187795,\n",
      "  \"finished_at\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"organization_id\": \"org-0n31SOlYOG0jXlq6NaGViQdx\",\n",
      "  \"result_files\": [],\n",
      "  \"status\": \"queued\",\n",
      "  \"validation_file\": null,\n",
      "  \"training_file\": \"file-vnVISeDU2iquWAzkHA7BVx55\",\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 3\n",
      "  },\n",
      "  \"trained_tokens\": null,\n",
      "  \"error\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "openai.FineTune.list()\n",
    "ft_obj = openai.FineTuningJob.create(training_file=file.id, model=\"gpt-3.5-turbo-0613\")\n",
    "print(ft_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-3.5-turbo-0613:phase-software::80kA8idB 2023-09-20 13:29:55\n",
      "ft:gpt-3.5-turbo-0613:phase-software::80jgPkkj 2023-09-20 12:59:11\n",
      "ft:gpt-3.5-turbo-0613:phase-software::7yEFQItN 2023-09-13 14:56:14\n",
      "ft:gpt-3.5-turbo-0613:phase-software::7vjB8xXr 2023-09-06 16:59:10\n",
      "ft:gpt-3.5-turbo-0613:phase-software::7viA7piB 2023-09-06 16:16:23\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "\n",
    "# Get a list of FineTuningJob objects\n",
    "ft_objs = openai.FineTuningJob.list()\n",
    "for f in ft_objs['data']:\n",
    "    print(f['fine_tuned_model'], datetime.datetime.fromtimestamp(f['created_at']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for fine-tune job to be finished. When finished, the model name will be listed: e.g. ft:gpt-3.5-turbo-0613:phase-software::80jgPkkj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succeeded\n",
      "ft:gpt-3.5-turbo-0613:phase-software::80kA8idB\n"
     ]
    }
   ],
   "source": [
    "print(openai.FineTuningJob.retrieve(id=ft_obj.id).status)\n",
    "ft_model = openai.FineTuningJob.retrieve(id=ft_obj.id).fine_tuned_model\n",
    "print(ft_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the newly trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ft(description, model_name):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are lottie file generator. lottie file should be inside code block ```json ```. format of lottie file: version is 5.12.1. layer is required. one shape should be in layer. a, p, o, r, s should be in both layer and shape,  hd = false. ip, op, sr, st should be in top level, layer, and shape. fill and transform should be parallel to shape json. for keyframe,  it should has two json objects with field i,o,s,t,ti,to.\"},\n",
    "            {\"role\": \"user\", \"content\": description}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of the result: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = apply_ft(\"generate lottie file label rotate 10 degrees and back\", \"ft:gpt-3.5-turbo-0613:phase-software::7yEFQItN\")\n",
    "with open('../../fine_tune_compare/ft_arrow_move_up_1.json', 'w') as outfile:\n",
    "    outfile.write(out)\n",
    "out = apply_ft(\"generate lottie file label rotate 10 degrees and back\", \"ft:gpt-3.5-turbo-0613:phase-software::80jgPkkj\")\n",
    "with open('../../fine_tune_compare/ft_arrow_move_up_2.json', 'w') as outfile:\n",
    "    outfile.write(out)\n",
    "out = apply_ft(\"generate lottie file label rotate 10 degrees and back\", \"ft:gpt-3.5-turbo-0613:phase-software::80kA8idB\")\n",
    "with open('../../fine_tune_compare/ft_arrow_move_up_3.json', 'w') as outfile:\n",
    "    outfile.write(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = apply_ft(\"generate lottie file half circle move up and down\", ft_model)\n",
    "with open('../../fine_tune_result/ft_circle_up_down.json', 'w') as outfile:\n",
    "    outfile.write(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = apply_ft(\"generate lottie file line rotate 360 degree\", ft_model)\n",
    "with open('../../fine_tune_result/ft_line_rotate.json', 'w') as outfile:\n",
    "    outfile.write(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = apply_ft(\"generate lottie file circle expanding and contracting\", ft_model)\n",
    "with open('../../fine_tune_result/ft_circle_expand.json', 'w') as outfile:\n",
    "    outfile.write(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion \n",
    "\n",
    "Even with a limited set of approximately 25 samples, fine-tuning has resulted in noticeable enhancements—eliminating the need for lengthy instructions to teach the Language Learning Model (LLM) the correct format. However, the current approach only allows for basic level instructions, such as converting \"flip square\" into a keyframe description like \"width 100% to 0% to 100%.\" One avenue for future exploration could be the development of a separate model tasked with translating human language into keyframe-based descriptions. These descriptions could then be used to generate JSON files, potentially boosting performance. Another interesting direction would be to experiment with multiple shapes and varying instructions to see if this leads to further improvements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promptviz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
