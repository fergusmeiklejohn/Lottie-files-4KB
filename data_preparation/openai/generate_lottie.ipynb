{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install OpenAI pakcages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall --yes openai\n",
    "!pip install --upgrade pip\n",
    "!pip install openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = <OPEN_AI_API_KEY>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-Tune OpenAI GPT3.5 model\n",
    "Step 1. generate >50 sample lottie animation instructions and save them as a JSON file named generated_prompt.json <br>\n",
    "Step 2. generate lottie files with GPT 4 model based on insturction in step 1<br>\n",
    "Step 3. manually import the generated lottie files into AE, and exportthem again (only keep 10-20 valid samples, other are not regonizable)<br>\n",
    "Step 4. construct fine-tune dataset with prompt and valid samples<br>\n",
    "Step 5. fine-tune openAI GPT3.5 with dataset<br>\n",
    "Step 6. apply fine-tuned model to generate new lottie animation files<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lottie_prompt(action):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are lottie file generator. lottie file should be inside code block ```json ```. format of lottie file: version is 5.12.1. layer is required. one shape should be in layer. a, p, o, r, s should be in both layer and shape,  hd = false. ip, op, sr, st should be in top level, layer, and shape. fill and transform should be parallel to shape json. for keyframe,  it should has two json objects with field i,o,s,t,ti,to.\"},\n",
    "        {\"role\": \"user\", \"content\": action}\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract json blob from GenAI response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_json_blob(paragraph):\n",
    "    # Define a regular expression pattern to match the JSON blob\n",
    "    pattern = r\"```json\\n(.+?)\\n```\"\n",
    "\n",
    "    # Use the re.search() function to find the first match of the pattern in the paragraph\n",
    "    match = re.search(pattern, paragraph, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        # If a match is found, extract the JSON blob from the match object\n",
    "        json_blob = match.group(1)\n",
    "\n",
    "        # Use the json.loads() function to parse the JSON blob into a Python object\n",
    "        json_obj = json.loads(json_blob)\n",
    "\n",
    "        # Return the Python object\n",
    "        return json_obj\n",
    "    else:\n",
    "        # If no match is found, return None\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate lottie files with gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('generated_prompt.json', 'r') as f:\n",
    "    o = json.load(f)\n",
    "    for json_obj in o['lottie_prompts'][:72]:\n",
    "        lo = generate_lottie_prompt(json_obj['description'])\n",
    "        try:\n",
    "            lo_extracted = extract_json_blob(lo)\n",
    "            print(lo_extracted)\n",
    "            if lo_extracted:\n",
    "                with open(f\"out/{json_obj['id']}.json\", 'w') as outfile:\n",
    "                    json.dump(lo_extracted, outfile)\n",
    "        except Exception as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create json blob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def create_json_object(number):\n",
    "    with open('./out/' + str(number) + '_ae.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        with open('generated_prompt.json', 'r') as lottie:\n",
    "            content = json.load(lottie)['lottie_prompts'][int(number)-1]['description']\n",
    "            json_obj = {\"messages\": [\n",
    "                            {\"role\": \"system\", \"content\": \"You are lottie file generator. lottie file should be inside code block ```json ```. format of lottie file: version is 5.12.1. layer is required. one shape should be in layer. a, p, o, r, s should be in both layer and shape,  hd = false. ip, op, sr, st should be in top level, layer, and shape. fill and transform should be parallel to shape json. for keyframe,  it should has two json objects with field i,o,s,t,ti,to.\"}, \n",
    "                            {\"role\": \"user\", \"content\": content}, \n",
    "                            {\"role\": \"assistant\", \"content\": json.dumps(data, ensure_ascii=False)}\n",
    "                        ]}\n",
    "        \n",
    "        return json_obj\n",
    "\n",
    "\n",
    "def create_jsonl(json_obj, output_file_path):\n",
    "    with open(output_file_path, 'a+') as f:\n",
    "        json.dump(json_obj, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 2, 4, 9, 25, 41, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77]:\n",
    "    create_jsonl(create_json_object(i), 'ft_0913.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the prepared dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file = openai.File.create(\n",
    "    file=open(\"ft_0913.jsonl\", \"rb\"),\n",
    "    purpose='fine-tune'\n",
    ")\n",
    "print(file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Fine-tune job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "openai.FineTune.list()\n",
    "ft_obj = openai.FineTuningJob.create(training_file=file.id, model=\"gpt-3.5-turbo-0613\")\n",
    "print(ft_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for fine-tune job to be finished. When finished, the model name will be listed: e.g. davinci:ft-personal-2023-08-15-02-12-49\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(openai.FineTuningJob.retrieve(id=ft_obj.id).status)\n",
    "ft_model = openai.FineTuningJob.retrieve(id=ft_obj.id).fine_tuned_model\n",
    "print(ft_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the newly trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ft(description, model_name):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are lottie file generator. lottie file should be inside code block ```json ```. format of lottie file: version is 5.12.1. layer is required. one shape should be in layer. a, p, o, r, s should be in both layer and shape,  hd = false. ip, op, sr, st should be in top level, layer, and shape. fill and transform should be parallel to shape json. for keyframe,  it should has two json objects with field i,o,s,t,ti,to.\"},\n",
    "            {\"role\": \"user\", \"content\": description}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of the result: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = apply_ft(\"generate lottie file pink circle move right to left in 3sec\", ft_model)\n",
    "with open('ft_pink_circle.json', 'w') as outfile:\n",
    "    outfile.write(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = apply_ft(\"generate lottie file red rectangle grow\", ft_model)\n",
    "with open('ft_red_rect_grow.json', 'w') as outfile:\n",
    "    outfile.write(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = apply_ft(\"generate lottie file blue rect move [0.0] to [50, 50] to [100, 50] to [0.0]\", ft_model)\n",
    "with open('ft_blue_rect_move_corners.json', 'w') as outfile:\n",
    "    outfile.write(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = apply_ft(\"generate lottie file red circle move around 4 corners\", ft_model)\n",
    "with open('ft_red_circle_move_corners.json', 'w') as outfile:\n",
    "    outfile.write(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = apply_ft(\"generate lottie file orangle circle flip\", ft_model)\n",
    "with open('ft_orangle_circle_flip.json', 'w') as outfile:\n",
    "    outfile.write(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion \n",
    "\n",
    "Even with a limited set of approximately 25 samples, fine-tuning has resulted in noticeable enhancements—eliminating the need for lengthy instructions to teach the Language Learning Model (LLM) the correct format. However, the current approach only allows for basic level instructions, such as converting \"flip square\" into a keyframe description like \"width 100% to 0% to 100%.\" One avenue for future exploration could be the development of a separate model tasked with translating human language into keyframe-based descriptions. These descriptions could then be used to generate JSON files, potentially boosting performance. Another interesting direction would be to experiment with multiple shapes and varying instructions to see if this leads to further improvements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promptviz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
